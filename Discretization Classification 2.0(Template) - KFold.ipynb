{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discretization Classification 2.0(Template) - KFold\n",
    "## Author: Ming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Package\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing \n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "#Discretization\n",
    "from mdlp.discretization import MDLP\n",
    "from caimcaim import CAIMD\n",
    "from scorecardbundle.feature_discretization import ChiMerge as cm\n",
    "from reportgen import preprocessing #Chimerge\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, accuracy_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "from threading import Thread, Lock\n",
    "lock = Lock()\n",
    "\n",
    "#Import Our Class\n",
    "%run \"TEJ Classification Package.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "data_name = \"Japanese_Bankrupt\"\n",
    "# data_name = \"Australian_Original\"\n",
    "#Discretize Good: Kaggle Tsai Bankruptcy Australia JPNCredit\n",
    "#\n",
    "if data_name == \"Tsai_Original\":\n",
    "    data_list,target_list,discretize_coloumn = ClassificationDataset().load_Tsai_BankruptcyData()\n",
    "elif  data_name == \"Germany_Original\":\n",
    "    data_list,target_list,discretize_coloumn = ClassificationDataset().load_German_Numeric_CreditData()\n",
    "elif  data_name == \"Germany_700-300(Random)\":\n",
    "    germanData_data_sample, discretize_coloumn = ClassificationDataset().load_German_Numeric_CreditData_Dataframe()\n",
    "elif  data_name == \"Australian_Original\":\n",
    "    data_list,target_list,discretize_coloumn = ClassificationDataset().load_Australian_CreditData()\n",
    "elif  data_name == \"Australian_Normalize(Old)\":\n",
    "    data_list,target_list,discretize_coloumn = ClassificationDataset().load_Australian_CreditData_Normalize()\n",
    "elif  data_name == \"Australian_(Dis5Column)Without12\":\n",
    "    data_list,target_list,discretize_coloumn = ClassificationDataset().load_Australian_CreditData_Different_Continuous_Column()\n",
    "elif  data_name == \"GiveMeSomeCredit\":\n",
    "    data_list,target_list,discretize_coloumn = ClassificationDataset().load_GiveMeSomeCredit_CreditData() \n",
    "elif  data_name == \"Japanese_Credit\":\n",
    "    data_list,target_list,discretize_coloumn = ClassificationDataset().load_Japanese_CreditData() \n",
    "elif  data_name == \"Japanese_Bankrupt\":\n",
    "    data_list,target_list,discretize_coloumn = ClassificationDataset().load_Japanese_BankruptData() \n",
    "elif  data_name == \"USA_Bankrupt\":\n",
    "    data_list,target_list,discretize_coloumn = ClassificationDataset().load_USA_BankruptData()\n",
    "elif  data_name == \"Bankruptcy\":\n",
    "    data_list,target_list,discretize_coloumn = ClassificationDataset().load_Bankruptcy_Data() \n",
    "elif  data_name == \"TEJCN\":\n",
    "    data_list,target_list,discretize_coloumn = ClassificationDataset().load_TEJCN_Data() \n",
    "elif  data_name == \"PAKDD\":\n",
    "    data_list,target_list,discretize_coloumn = ClassificationDataset().load_PAKDD_Data() \n",
    "    \n",
    "# # Select Data\n",
    "# data_list = tsaiData_data\n",
    "# target_list = tsaiData_target\n",
    "# discretize_coloumn = continuous_coloumn\n",
    "\n",
    "# Sampling\n",
    "# large = germanData_data_sample.loc[germanData_data_sample['default'] == 1]\n",
    "# small = germanData_data_sample.loc[germanData_data_sample['default'] == 2]\n",
    "# large = large.sample(n=300)\n",
    "# germanData_data = pd.concat([large, small])\n",
    "# germanData_data = germanData_data.sample(frac=1).reset_index(drop=True)\n",
    "# data_list = germanData_data[[i for i in germanData_data.columns if i != 'default']].values\n",
    "# target_list = germanData_data[[i for i in germanData_data.columns if i == 'default']].values\n",
    "\n",
    "\n",
    "# Declare Result List (Alogorithm, fold, ACC, AUC)\n",
    "evaluation_result_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print (\"資料筆數 ::\", data_list.shape[0])\n",
    "print (\"特徵數量(不含Target) ::\", data_list.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "大類:1 小類2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(target_list, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "a = pd.DataFrame(data_list)\n",
    "\n",
    "for idx,classifi in enumerate(a):\n",
    "    if a[idx].nunique()>10:\n",
    "        print(str(idx)+\"_\"+str(a[idx].nunique()))\n",
    "        #print(str(idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Specific Features to Discretization + Discretization Method (MDLP、CAIM、ChiMerge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discretization:\n",
    "    def __init__(self, training_data, training_target, discretize_coloumn):\n",
    "        self.training_data = training_data\n",
    "        self.training_target = training_target\n",
    "        self.discretize_coloumn = discretize_coloumn\n",
    "        self.transformer_MDLP = MDLP()\n",
    "        self.transformer_CAIMD = CAIMD()\n",
    "        self.transformer_ChiMerge_SC = cm.ChiMerge(output_dataframe=True, confidence_level=0.95)\n",
    "        self.transformer_ChiMerge_RG = preprocessing.Discretization(method='chimerge')\n",
    "\n",
    "    def SelectFeatures(self): ##Split Specific to Discretize\n",
    "        idx_IN_columns = self.discretize_coloumn\n",
    "        idx_OUT_columns = [i for i in range(np.shape(self.training_data)[1]) if i not in idx_IN_columns]\n",
    "        selectData_list = self.training_data[:,idx_IN_columns]\n",
    "        disSelectData_list = self.training_data[:,idx_OUT_columns]\n",
    "        return selectData_list , disSelectData_list\n",
    "        \n",
    "    def MDLP(self,selectData_list): \n",
    "        selectDataDiscretiz_list = self.transformer_MDLP.fit_transform(selectData_list, self.training_target)\n",
    "        return selectDataDiscretiz_list\n",
    "    \n",
    "    def MDLP_transform(self,selectData_test_list): \n",
    "        selectDataDiscretiz_list = self.transformer_MDLP.transform(selectData_test_list)\n",
    "        return selectDataDiscretiz_list\n",
    "\n",
    "    def CAIMD(self,selectData_list):  #CAIMD\n",
    "        selectDataDiscretiz_list = self.transformer_CAIMD.fit_transform(selectData_list, self.training_target)\n",
    "        return selectDataDiscretiz_list\n",
    "    \n",
    "    def CAIMD_transform(self,selectData_test_list):  #CAIMD\n",
    "        selectDataDiscretiz_list = self.transformer_CAIMD.transform(selectData_test_list)\n",
    "        return selectDataDiscretiz_list\n",
    "    \n",
    "    def ChiMerge_SC(self,selectData_list):  #Chimerge\n",
    "        selectDataDiscretiz_list = self.transformer_ChiMerge_SC.fit_transform(selectData_list, self.training_target.squeeze())\n",
    "        return self.Box_Transform(selectDataDiscretiz_list)\n",
    "    \n",
    "    def ChiMerge_SC_transform(self,selectData_test_list):  #Chimerge\n",
    "        selectDataDiscretiz_list = self.transformer_ChiMerge_SC.transform(selectData_test_list)\n",
    "        return self.Box_Transform(selectDataDiscretiz_list)\n",
    "    \n",
    "    def ChiMerge_RG(self,selectData_list):  #Chimerge\n",
    "        selectDataDiscretiz_list = self.transformer_ChiMerge_RG.fit_transform(selectData_list, self.training_target.squeeze())\n",
    "        return self.Box_Transform(selectDataDiscretiz_list)\n",
    "    \n",
    "    def ChiMerge_RG_transform(self,selectData_test_list):  #Chimerge\n",
    "        selectDataDiscretiz_list = self.transformer_ChiMerge_RG.transform(selectData_test_list)\n",
    "        return self.Box_Transform(selectDataDiscretiz_list)\n",
    "    \n",
    "    def Box_Transform(self,discretize_list):\n",
    "        for i in discretize_list.columns:\n",
    "            replace_coloumn = discretize_list[i].unique()\n",
    "            replace_coloumn.sort()\n",
    "            lst = list(replace_coloumn)\n",
    "            ip_dict = dict(zip(lst, range(len(lst))))\n",
    "            discretize_list[i] = discretize_list[i].replace(ip_dict)\n",
    "        return discretize_list\n",
    "    \n",
    "    def MergeFeatures(self,selectDataDiscretiz_list,disSelectData_list):  ## Merge Discretized Data with Original Data\n",
    "        self.dataDiscretize_list = np.concatenate([selectDataDiscretiz_list,disSelectData_list],axis = 1)\n",
    "        return self.dataDiscretize_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KFoldFuntion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KFoldFuntion:\n",
    "    # linear_svc,'linear_svc','baseline', data_list, target_list, fold\n",
    "    def __init__(self, classifier, classifier_name, method, data_list, target_list, fold, discretize_coloumn):\n",
    "        self.X = data_list\n",
    "        self.y = target_list\n",
    "        self.fold = fold\n",
    "        self.outcomes_acc = []\n",
    "        self.outcomes_auc = []\n",
    "        self.outcomes_typeII = []\n",
    "        self.outcomes_typeI = []\n",
    "        self.fold_result_list = []\n",
    "        self.outcomes_minority = []\n",
    "        self.outcomes_majority = []\n",
    "        self.method = method  # (Baseline, MDLP, CAIM)\n",
    "        self.classifier = classifier\n",
    "        self.classifier_name = classifier_name\n",
    "        self.discretize_coloumn = discretize_coloumn\n",
    "    \n",
    "    def Classify(self):\n",
    "        kf = KFold(n_splits=self.fold,random_state=np.random, shuffle=True)\n",
    "        #kf = StratifiedKFold(n_splits=self.fold)\n",
    "        #for train_index, test_index in kf.split(self.X,self.y):\n",
    "        for train_index, test_index in kf.split(self.X):\n",
    "            X_train, X_test = self.X[train_index], self.X[test_index] #X_train: training data X_test: testing data\n",
    "            y_train, y_test = self.y[train_index], self.y[test_index] #y_train: training data answer y_test: testing data answer\n",
    "            \n",
    "            if self.method == 'Baseline':\n",
    "                \n",
    "                # Convert to Dataframe\n",
    "                X_train_dataframe = pd.DataFrame(X_train)\n",
    "                X_test_dataframe  = pd.DataFrame(X_test)\n",
    "                y_train_dataframe = pd.DataFrame(y_train)\n",
    "                y_test_dataframe  = pd.DataFrame(y_test)\n",
    "                predictions,proba = self.Classification(X_train_dataframe,y_train_dataframe,X_test_dataframe,y_test_dataframe)\n",
    "                self.StoreFoldResult(y_test_dataframe,predictions,proba)\n",
    "            else:\n",
    "\n",
    "                # Declare Training Data Discretizer\n",
    "                discretize_train = Discretization(X_train,y_train,self.discretize_coloumn)\n",
    "\n",
    "                # Select Discretize Feature (Training Data Continous Feature)\n",
    "                selectData_list, disSelectData_list  = discretize_train.SelectFeatures() #Devide Discretize Coloumns\n",
    "\n",
    "                \n",
    "                \n",
    "                # Discretize(Train)\n",
    "                if self.method == 'MDLP':\n",
    "                    selectDataDiscretiz_list = discretize_train.MDLP(selectData_list)\n",
    "                elif self.method == 'CAIMD':\n",
    "                    selectDataDiscretiz_list = discretize_train.CAIMD(selectData_list)\n",
    "                elif self.method == 'ChiMerge_SC':\n",
    "                    selectDataDiscretiz_list = discretize_train.ChiMerge_SC(selectData_list)\n",
    "                elif self.method == 'ChiMerge_RG':\n",
    "                    selectDataDiscretiz_list = discretize_train.ChiMerge_RG(selectData_list)\n",
    "                # Merge dis_feature & categeorial_feature\n",
    "                X_train_dis = discretize_train.MergeFeatures(selectDataDiscretiz_list,disSelectData_list)\n",
    "\n",
    "                # Declare Testing Data Discretizer\n",
    "                discretize_test = Discretization(X_test,y_test,discretize_coloumn)\n",
    "\n",
    "                # Select Discretize Feature (Testing Data Continous Feature)\n",
    "                selectData_test_list, disSelectData_test_list  = discretize_test.SelectFeatures()\n",
    "\n",
    "                \n",
    "                \n",
    "                # Employ Training Data Cutpoint\n",
    "                if self.method == 'MDLP':\n",
    "                    selectDataDiscretiz_test_list = discretize_train.MDLP_transform(selectData_test_list)\n",
    "                elif self.method == 'CAIMD':\n",
    "                    selectDataDiscretiz_test_list = discretize_train.CAIMD_transform(selectData_test_list)\n",
    "                elif self.method == 'ChiMerge_SC':\n",
    "                    selectDataDiscretiz_test_list = discretize_train.ChiMerge_SC_transform(selectData_test_list)\n",
    "                elif self.method == 'ChiMerge_RG':\n",
    "                    selectDataDiscretiz_test_list = discretize_train.ChiMerge_RG_transform(selectData_test_list)\n",
    "                    \n",
    "                # Merge dis_feature & categeorial_feature\n",
    "                X_test_dis = discretize_test.MergeFeatures(selectDataDiscretiz_test_list,disSelectData_test_list)\n",
    "\n",
    "                # Convert to Dataframe\n",
    "                X_train_dis_dataframe = pd.DataFrame(X_train_dis)\n",
    "                X_test_dis_dataframe = pd.DataFrame(X_test_dis)\n",
    "                y_train_dataframe = pd.DataFrame(y_train)\n",
    "                y_test_dataframe = pd.DataFrame(y_test)\n",
    "\n",
    "                # Prediction\n",
    "                predictions,proba = self.Classification(X_train_dis_dataframe,y_train_dataframe,X_test_dis_dataframe,y_test_dataframe)\n",
    "                self.StoreFoldResult(y_test_dataframe,predictions,proba)\n",
    "        return self.PrintTotalResult()   \n",
    "                      \n",
    "    def Classification(self,X_train_dataframe,y_train_dataframe,X_test_dataframe,y_test_dataframe):\n",
    "        clf = self.classifier\n",
    "        clf.fit(X_train_dataframe, y_train_dataframe[0].ravel())\n",
    "        predictions = clf.predict(X_test_dataframe)\n",
    "        proba = clf.predict_proba(X_test_dataframe)[:, 1]\n",
    "        return predictions,proba\n",
    "\n",
    "    \n",
    "    def StoreFoldResult(self,y_test_dataframe,predictions,proba):\n",
    "        \n",
    "        #Accuracy Score\n",
    "        accuracy = accuracy_score(y_test_dataframe, predictions)\n",
    "        self.outcomes_acc.append(accuracy)\n",
    "        \n",
    "        #AUC Score\n",
    "        auc = roc_auc_score(y_test_dataframe, proba)\n",
    "        self.outcomes_auc.append(auc)\n",
    "        \n",
    "        #Type II Error\n",
    "        TN, FP, FN, TP = confusion_matrix(y_test_dataframe, predictions).ravel()\n",
    "        typeII = FN/(TP+FN)\n",
    "        typeI = FP/(FP+TN)\n",
    "        self.outcomes_typeII.append(typeII)\n",
    "        self.outcomes_typeI.append(typeI)\n",
    "        \n",
    "        #Majority, Minority (Count)\n",
    "        unique, counts = np.unique(y_test_dataframe, return_counts=True)\n",
    "        dict(zip(unique, counts))\n",
    "        \n",
    "        proportion = np.unique(y_test_dataframe, return_counts=True)\n",
    "        majority_proportion = proportion[1][0]/(self.X.shape[0]/self.fold)\n",
    "        minority_proportion = proportion[1][1]/(self.X.shape[0]/self.fold)\n",
    "        self.outcomes_majority.append(proportion[1][0])\n",
    "        self.outcomes_minority.append(proportion[1][1])\n",
    "\n",
    "        \n",
    "        # Plot fold_result_list \n",
    "        each_fold_result_list = [accuracy,auc,typeI,typeII,majority_proportion,minority_proportion]\n",
    "        self.fold_result_list.append(each_fold_result_list)\n",
    "    \n",
    "    def PrintTotalResult(self):\n",
    "        \n",
    "        mean_outcome_acc = np.mean(self.outcomes_acc)\n",
    "        print(\"Mean Accuracy: {0}\".format(mean_outcome_acc))\n",
    "        print(\"Mean Accuracy\"+ str(self.outcomes_acc))\n",
    "        \n",
    "        mean_outcome_auc = np.mean(self.outcomes_auc)\n",
    "        print(\"Mean Auc: {0}\".format(mean_outcome_auc))\n",
    "        print(\"Mean Auc\"+ str(self.outcomes_auc))\n",
    "        \n",
    "        mean_outcomes_typeII = np.mean(self.outcomes_typeII)\n",
    "        print(\"Mean TypeII: {0}\".format(mean_outcomes_typeII))\n",
    "        print(\"Mean TypeII\"+ str(self.outcomes_typeII))\n",
    "        \n",
    "        mean_outcomes_typeI = np.mean(self.outcomes_typeI)\n",
    "        print(\"Mean TypeI: {0}\".format(mean_outcomes_typeI))\n",
    "        print(\"Mean TypeI\"+ str(self.outcomes_typeI))\n",
    "        \n",
    "        lock.acquire()\n",
    "        \n",
    "        # Print Each Fold Plot\n",
    "        self.PrintPlotEachFold(self.fold_result_list,\"Result\")\n",
    "        \n",
    "        lock.release()\n",
    "        \n",
    "        return mean_outcome_acc, mean_outcome_auc, mean_outcomes_typeI, mean_outcomes_typeII\n",
    "    \n",
    "    def PrintPlotEachFold(self,plot_data,metrics_name):\n",
    "        \n",
    "        #Trasnfer Type \n",
    "        plot_data = np.array(plot_data)\n",
    "        \n",
    "        #Set Each Line Data\n",
    "        plt.plot(plot_data[:,0],label='acc')\n",
    "        plt.plot(plot_data[:,1],label='auc')\n",
    "        plt.plot(plot_data[:,2],label='type I')\n",
    "        plt.plot(plot_data[:,3],label='type II')\n",
    "        plt.plot(plot_data[:,4],label='maj', marker='o')\n",
    "        plt.plot(plot_data[:,5],label='min', marker='o')\n",
    "        \n",
    "        #Set Graph Information\n",
    "        title = '{metrics_name} with {fold} folds-{method}-{classifier_name}'.format(\n",
    "            metrics_name=metrics_name, fold=self.fold,method=self.method,classifier_name=self.classifier_name )\n",
    "        plt.title(title)\n",
    "        plt.xlabel('Folds')\n",
    "        plt.ylabel('percertange')\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def CompareMethodMeanResult(data_name, clf_name, rounds,result_10times_baseline,result_10times_MDLP,result_10times_CAIM,result_10times_ChiMerge_SC):\n",
    "    #Labels\n",
    "    labels = ['ACC', 'AUC', 'TYPEI', 'TYPEII']\n",
    "    x = np.arange(len(labels))  # the label locations\n",
    "    width = 0.15  # the width of the bars\n",
    "\n",
    "    result_10times_baseline_mean = np.around( np.mean(result_10times_baseline, axis=0), decimals=3)\n",
    "    result_10times_MDLP_mean =  np.around( np.mean(result_10times_MDLP, axis=0), decimals=3)\n",
    "    result_10times_CAIM_mean =  np.around( np.mean(result_10times_CAIM, axis=0), decimals=3)\n",
    "    result_10times_ChiMerge_SC_mean =  np.around( np.mean(result_10times_ChiMerge_SC, axis=0), decimals=3)\n",
    "    #result_10times_ChiMerge_RG_mean =  np.around( np.mean(result_10times_ChiMerge_RG, axis=0), decimals=3)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(15, 10))\n",
    "    rects1 = ax.bar(x , result_10times_baseline_mean, width, label='Baseline')\n",
    "    rects2 = ax.bar(x +width, result_10times_MDLP_mean, width, label='MDLP')\n",
    "    rects3 = ax.bar(x +width*2, result_10times_CAIM_mean, width, label='CAIM')\n",
    "    rects4 = ax.bar(x +width*3, result_10times_ChiMerge_SC_mean, width, label='ChiMerge_SC(0.95)')\n",
    "    #rects5 = ax.bar(x +width*4, result_10times_ChiMerge_RG_mean, width, label='ChiMerge_RG')\n",
    "\n",
    "    # Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "    ax.set_ylabel('Percentage')\n",
    "    data_name, clf_name, rounds\n",
    "    title = 'Compare Result-{data_name}-{classifier_name}'.format(data_name=data_name,classifier_name=clf_name)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xticks(x+width)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.legend(bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "    def autolabel(rects):\n",
    "        \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
    "        for rect in rects:\n",
    "            height = rect.get_height()\n",
    "            ax.annotate('{}'.format(height),\n",
    "                        xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                        xytext=(0, 5),  # 3 points vertical offset\n",
    "                        textcoords=\"offset points\",\n",
    "                        ha='center', va='bottom', size = 12)\n",
    "    autolabel(rects1)\n",
    "    autolabel(rects2)\n",
    "    autolabel(rects3)\n",
    "    autolabel(rects4)\n",
    "    #autolabel(rects5)\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    file_time = time.strftime(\"%Y-%m-%d-%H%M%S\", time.localtime()) \n",
    "    file_name = \"results/{title}_{file_timeA}.png\".format(file_timeA = file_time, title= title)\n",
    "    print(title)\n",
    "    fig.savefig(file_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResultEachMethodLineChart(result, method_name,data_name, classifier_name):\n",
    "    result = np.array(result)\n",
    "    \n",
    "    plt.plot(result[:,0], label='Acc', marker='o')\n",
    "    plt.plot(result[:,1], label='Auc', marker='o')\n",
    "    plt.plot(result[:,2], label='TypeI', marker='o')\n",
    "    plt.plot(result[:,3], label='TypeII', marker='o')\n",
    "    plt.legend(bbox_to_anchor=(1, 0.5))\n",
    "    plt.ylabel('Percertange')\n",
    "    plt.xlabel('Rounds')\n",
    "    title = 'Each Rounds-{data_name}-{method_name}-{classifier_name}'.format(data_name=data_name,method_name=method_name,classifier_name=classifier_name)\n",
    "    plt.title(title)\n",
    "    \n",
    "    \n",
    "    file_time = time.strftime(\"%Y-%m-%d-%H%M%S\", time.localtime()) \n",
    "    #plt.savefig('results/{title}_{file_timeA}.png'.format(file_timeA = file_time, title= title, method_name=method_name, classifier_name=classifier_name), bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Classification Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC, LinearSVC , libsvm\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from logitboost import LogitBoost\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Classify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run 10 Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Classifcation Method\n",
    "linear_svc = CalibratedClassifierCV(LinearSVC(max_iter=7000))\n",
    "svmlinear = SVC(kernel='linear', probability=True)\n",
    "svmrbf = SVC(kernel='rbf', probability=True)\n",
    "DecisionTreeClassifier = tree.DecisionTreeClassifier()\n",
    "RandomForest = RandomForestClassifier()\n",
    "logisticRegression = LogisticRegression()\n",
    "mlp = MLPClassifier()\n",
    "xgBoost = xgb.XGBClassifier()\n",
    "GaussianNaiveBayes = GaussianNB()\n",
    "MultinomialNaiveBayes = MultinomialNB()\n",
    "ComplementNaiveBayes = ComplementNB()\n",
    "lboost = LogitBoost()\n",
    "ada = AdaBoostClassifier()\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "##########################################\n",
    "#svmpoly = SVC(kernel='poly', probability=True)\n",
    "#neigh = KNeighborsRegressor(n_neighbors=5)\n",
    "#linearRegression= LinearRegression()\n",
    "\n",
    "#DecisionTreeClassifier,logisticRegression,mlp,xgBoost\n",
    "# classifier_list = [svmrbf,DecisionTreeClassifier,RandomForest,logisticRegression,mlp,xgBoost ]\n",
    "# classifier_name_list = ['svmrbf','DecisionTreeClassifier','RandomForest','LogisticRegression','MLPClassifier','xgBoost' ]\n",
    "def run10times(classifier_list,classifier_name_list):\n",
    "\n",
    "    classifier_list = [classifier_list]\n",
    "    classifier_name_list = [classifier_name_list]\n",
    "        \n",
    "    classifier_result_list = []\n",
    "\n",
    "\n",
    "\n",
    "    for idx,classifi in enumerate(classifier_list):\n",
    "\n",
    "        result_list = []\n",
    "        rounds = 2\n",
    "        clf_name = classifier_name_list[idx]\n",
    "        for i in range(1,rounds):\n",
    "\n",
    "            result_list.clear()\n",
    "            result_10times_baseline = []\n",
    "            result_10times_MDLP = []\n",
    "            result_10times_CAIM = []\n",
    "            result_10times_ChiMerge_SC = []\n",
    "            result_10times_ChiMerge_RG = []\n",
    "            runnung_time_list = []\n",
    "            #Method Select\n",
    "\n",
    "            clf = classifi\n",
    "            fold = 5\n",
    "\n",
    "            start_time = time.time()\n",
    "            result_eachtimes_baseline = KFoldFuntion(clf, clf_name, 'Baseline', data_list, target_list, fold, discretize_coloumn).Classify()\n",
    "            result_10times_baseline.append(result_eachtimes_baseline)\n",
    "            print(\"Mean : {0}\".format(np.mean(result_10times_baseline, axis=0)))\n",
    "            runnung_time_list.append(time.time() - start_time)\n",
    "\n",
    "            start_time = time.time()\n",
    "            result_eachtimes_MDLP = KFoldFuntion(clf, clf_name, 'MDLP', data_list, target_list, fold, discretize_coloumn).Classify()\n",
    "            result_10times_MDLP.append(result_eachtimes_MDLP)\n",
    "            runnung_time_list.append(time.time() - start_time)\n",
    "\n",
    "            start_time = time.time()\n",
    "            result_eachtimes_CAIM = KFoldFuntion(clf, clf_name, 'CAIMD', data_list, target_list, fold, discretize_coloumn).Classify()\n",
    "            result_10times_CAIM.append(result_eachtimes_CAIM)\n",
    "            runnung_time_list.append(time.time() - start_time)\n",
    "\n",
    "            start_time = time.time()\n",
    "            result_eachtimes_ChiMerge_SC = KFoldFuntion(clf, clf_name, 'ChiMerge_SC', data_list, target_list, fold, discretize_coloumn).Classify()\n",
    "            result_10times_ChiMerge_SC.append(result_eachtimes_ChiMerge_SC)\n",
    "            runnung_time_list.append(time.time() - start_time)\n",
    "    \n",
    "        \n",
    "        # Thread Lock\n",
    "        lock.acquire()\n",
    "        \n",
    "        \n",
    "        # Compare Chart (Same Classifier)\n",
    "        CompareMethodMeanResult(data_name, clf_name, rounds,result_10times_baseline,result_10times_MDLP,result_10times_CAIM,result_10times_ChiMerge_SC)\n",
    "\n",
    "\n",
    "        # Compare Chart (Same Classifier)\n",
    "        ResultEachMethodLineChart(result_10times_baseline,\"Baseline\",data_name,clf_name)\n",
    "        ResultEachMethodLineChart(result_10times_MDLP,\"MDLP\",data_name,clf_name)\n",
    "        ResultEachMethodLineChart(result_10times_CAIM,\"CAIM\",data_name,clf_name)\n",
    "        ResultEachMethodLineChart(result_10times_ChiMerge_SC,\"ChiMerge_SC\",data_name,clf_name)\n",
    "\n",
    "        result_list.append(np.mean(result_10times_baseline, axis=0))\n",
    "        result_list.append(np.mean(result_10times_MDLP, axis=0))\n",
    "        result_list.append(np.mean(result_10times_CAIM, axis=0))\n",
    "        result_list.append(np.mean(result_10times_ChiMerge_SC, axis=0))\n",
    "\n",
    "        # Single Classify Method \n",
    "        result_with_method = pd.DataFrame(result_list, index=['Baseline','MDLP','CAIM','ChiMerge'], columns=['Accuracy','AUC','TypeI','TypeII'])\n",
    "        result_with_method['Time(Second)'] = runnung_time_list\n",
    "        print(result_with_method)\n",
    "\n",
    "        file_time = time.strftime(\"%Y-%m-%d-%H%M%S\", time.localtime()) \n",
    "        file_name = \"Classifier_result_list_{fold}Fold_{data_name}_{method}_{file_timeA}.xlsx\".format(fold = fold, file_timeA = file_time,data_name=data_name,method=clf_name)\n",
    "        pd.DataFrame(result_with_method).to_excel(\"resultsexcel/\"+file_name)\n",
    "        \n",
    "        \n",
    "        # Thread Unlock\n",
    "        lock.release()\n",
    "    \n",
    "\n",
    "\n",
    "t0 = Thread(target=run10times,args=(svmlinear,\"svmlinear\"))\n",
    "t1 = Thread(target=run10times,args=(linear_svc,\"linear_svc\"))\n",
    "t2 = Thread(target=run10times,args=(svmrbf,\"svmrbf\"))\n",
    "t3 = Thread(target=run10times,args=(DecisionTreeClassifier,\"DecisionTreeClassifier\"))\n",
    "t4 = Thread(target=run10times,args=(RandomForest,\"RandomForest\"))\n",
    "t5 = Thread(target=run10times,args=(logisticRegression,\"logisticRegression\"))\n",
    "t6 = Thread(target=run10times,args=(mlp,\"mlp\"))\n",
    "t7 = Thread(target=run10times,args=(xgBoost,\"xgBoost\"))\n",
    "t8 = Thread(target=run10times,args=(GaussianNaiveBayes,\"GaussianNaiveBayes\"))\n",
    "t9 = Thread(target=run10times,args=(lboost,\"LogitBoost\"))\n",
    "t10 = Thread(target=run10times,args=(ada,\"AdaBoost\"))\n",
    "t11 = Thread(target=run10times,args=(knn,\"KNN\"))\n",
    "\n",
    "\n",
    "#thread_list = [t1,t2,t3,t4,t5,t6,t7,t8,t9,t10,t0]\n",
    "thread_list = [t11]\n",
    "#thread_list = [t11,t10,t9,t7,t8]\n",
    "\n",
    "#程式開始\n",
    "for item in thread_list:\n",
    "    item.start()\n",
    "print(\"\\n程式開始\")\n",
    "\n",
    "\n",
    "#程式結束\n",
    "for item in thread_list:\n",
    "    item.join()\n",
    "print(\"\\n程式結束\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#############################################################################YEE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Record Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "title = 'Compare Result-{data_name}-{classifier_name}'.format(data_name=data_name,classifier_name=clf_name)\n",
    "with pd.ExcelWriter('output.xlsx') as writer:  # doctest: +SKIP\n",
    "        df1.to_excel(writer, sheet_name='Sheet_name_1')\n",
    "        df2.to_excel(writer, sheet_name='Sheet_name_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "file_time = time.strftime(\"%Y-%m-%d-%H%M%S\", time.localtime()) \n",
    "file_name = \"result_10times_baseline_{file_timeA}.xlsx\".format(file_timeA = file_time)\n",
    "pd.DataFrame(result_10times_baseline).to_excel(file_name, header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "print(\"Mean : {0}\".format(np.mean(result_10times_baseline, axis=0))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "print(\"Mean : {0}\".format(np.mean(result_10times_MDLP, axis=0))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(\"Mean : {0}\".format(np.mean(result_10times_CAIM, axis=0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(\"Mean : {0}\".format(np.mean(result_10times_ChiMerge_SC, axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#ResultEachMethodLineChart(result_10times_ChiMerge_RG,\"ChiMerge_RG\",data_name,clf_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
