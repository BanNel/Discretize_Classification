{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discretization Classification 2.0(Template) - KFold\n",
    "## Author: Ming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Package\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing \n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "#Discretization\n",
    "# from mdlp.discretization import MDLP\n",
    "# from caimcaim import CAIMD\n",
    "# from scorecardbundle.feature_discretization import ChiMerge as cm\n",
    "# from reportgen import preprocessing #Chimerge\n",
    "\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, accuracy_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "from threading import Thread, Lock\n",
    "lock = Lock()\n",
    "\n",
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects import pandas2ri\n",
    "pandas2ri.activate()\n",
    "\n",
    "#Import Our Class\n",
    "%run \"TEJ Classification Package.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "data_name = \"TEJCN\"\n",
    "#Fast: Japanese_Credit Australian_Original Germany_Original Japanese_Bankrupt \n",
    "#Slow: USA_Bankrupt\n",
    "\n",
    "#Discretize Good: Kaggle Tsai Bankruptcy Australia JPNCredit\n",
    "#\n",
    "if data_name == \"Tsai_Original\":\n",
    "    data_list,target_list,discretize_coloumn = ClassificationDataset().load_Tsai_BankruptcyData()\n",
    "elif  data_name == \"Germany_Original\":\n",
    "    data_list,target_list,discretize_coloumn = ClassificationDataset().load_German_Numeric_CreditData()\n",
    "elif  data_name == \"Germany_700-300(Random)\":\n",
    "    germanData_data_sample, discretize_coloumn = ClassificationDataset().load_German_Numeric_CreditData_Dataframe()\n",
    "elif  data_name == \"Australian_Original\":\n",
    "    data_list,target_list,discretize_coloumn = ClassificationDataset().load_Australian_CreditData()\n",
    "elif  data_name == \"Australian_Normalize(Old)\":\n",
    "    data_list,target_list,discretize_coloumn = ClassificationDataset().load_Australian_CreditData_Normalize()\n",
    "elif  data_name == \"Australian_(Dis5Column)Without12\":\n",
    "    data_list,target_list,discretize_coloumn = ClassificationDataset().load_Australian_CreditData_Different_Continuous_Column()\n",
    "elif  data_name == \"GiveMeSomeCredit\":\n",
    "    data_list,target_list,discretize_coloumn = ClassificationDataset().load_GiveMeSomeCredit_CreditData() \n",
    "elif  data_name == \"Japanese_Credit\":\n",
    "    data_list,target_list,discretize_coloumn = ClassificationDataset().load_Japanese_CreditData() \n",
    "elif  data_name == \"Japanese_Bankrupt\":\n",
    "    data_list,target_list,discretize_coloumn = ClassificationDataset().load_Japanese_BankruptData() \n",
    "elif  data_name == \"USA_Bankrupt\":\n",
    "    data_list,target_list,discretize_coloumn = ClassificationDataset().load_USA_BankruptData()\n",
    "elif  data_name == \"Bankruptcy\":\n",
    "    data_list,target_list,discretize_coloumn = ClassificationDataset().load_Bankruptcy_Data() \n",
    "elif  data_name == \"TEJCN\":\n",
    "    data_list,target_list,discretize_coloumn = ClassificationDataset().load_TEJCN_Data() \n",
    "elif  data_name == \"PAKDD\":\n",
    "    data_list,target_list,discretize_coloumn = ClassificationDataset().load_PAKDD_Data() \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling\n",
    "# large = germanData_data_sample.loc[germanData_data_sample['default'] == 1]\n",
    "# small = germanData_data_sample.loc[germanData_data_sample['default'] == 2]\n",
    "# large = large.sample(n=300)\n",
    "# germanData_data = pd.concat([large, small])\n",
    "# germanData_data = germanData_data.sample(frac=1).reset_index(drop=True)\n",
    "# data_list = germanData_data[[i for i in germanData_data.columns if i != 'default']].values\n",
    "# target_list = germanData_data[[i for i in germanData_data.columns if i == 'default']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print (\"資料筆數 ::\", data_list.shape[0])\n",
    "print (\"特徵數量(不含Target) ::\", data_list.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(target_list, return_counts=True)\n",
    "dict(zip(unique, counts)) #Major:1 ; minor2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discretization_Python\n",
    "Select Specific Features to Discretization + Discretization Method (MDLP、CAIM、ChiMerge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class Discretization:\n",
    "    def __init__(self, training_data, training_target, discretize_coloumn):\n",
    "        self.training_data = training_data\n",
    "        self.training_target = training_target\n",
    "        self.discretize_coloumn = discretize_coloumn\n",
    "        self.transformer_MDLP = MDLP()\n",
    "        self.transformer_CAIMD = CAIMD()\n",
    "        self.transformer_ChiMerge_SC = cm.ChiMerge(output_dataframe=True)\n",
    "        self.transformer_ChiMerge_RG = preprocessing.Discretization(method='chimerge')\n",
    "\n",
    "    def SelectFeatures(self): ##Split Specific to Discretize\n",
    "        idx_IN_columns = self.discretize_coloumn\n",
    "        idx_OUT_columns = [i for i in range(np.shape(self.training_data)[1]) if i not in idx_IN_columns]\n",
    "        selectData_list = self.training_data[:,idx_IN_columns]\n",
    "        disSelectData_list = self.training_data[:,idx_OUT_columns]\n",
    "        return selectData_list , disSelectData_list\n",
    "        \n",
    "    def MDLP(self,selectData_list): \n",
    "        selectDataDiscretiz_list = self.transformer_MDLP.fit_transform(selectData_list, self.training_target)\n",
    "        return selectDataDiscretiz_list\n",
    "    \n",
    "    def MDLP_transform(self,selectData_test_list): \n",
    "        selectDataDiscretiz_list = self.transformer_MDLP.transform(selectData_test_list)\n",
    "        return selectDataDiscretiz_list\n",
    "\n",
    "    def CAIMD(self,selectData_list):  #CAIMD\n",
    "        selectDataDiscretiz_list = self.transformer_CAIMD.fit_transform(selectData_list, self.training_target)\n",
    "        return selectDataDiscretiz_list\n",
    "    \n",
    "    def CAIMD_transform(self,selectData_test_list):  #CAIMD\n",
    "        selectDataDiscretiz_list = self.transformer_CAIMD.transform(selectData_test_list)\n",
    "        return selectDataDiscretiz_list\n",
    "    \n",
    "    def ChiMerge_SC(self,selectData_list):  #Chimerge\n",
    "        selectDataDiscretiz_list = self.transformer_ChiMerge_SC.fit_transform(selectData_list, self.training_target.squeeze())\n",
    "        return self.Box_Transform(selectDataDiscretiz_list)\n",
    "    \n",
    "    def ChiMerge_SC_transform(self,selectData_test_list):  #Chimerge\n",
    "        selectDataDiscretiz_list = self.transformer_ChiMerge_SC.transform(selectData_test_list)\n",
    "        return self.Box_Transform(selectDataDiscretiz_list)\n",
    "    \n",
    "    def ChiMerge_RG(self,selectData_list):  #Chimerge\n",
    "        selectDataDiscretiz_list = self.transformer_ChiMerge_RG.fit_transform(selectData_list, self.training_target.squeeze())\n",
    "        return self.Box_Transform(selectDataDiscretiz_list)\n",
    "    \n",
    "    def ChiMerge_RG_transform(self,selectData_test_list):  #Chimerge\n",
    "        selectDataDiscretiz_list = self.transformer_ChiMerge_RG.transform(selectData_test_list)\n",
    "        return self.Box_Transform(selectDataDiscretiz_list)\n",
    "    \n",
    "    def Box_Transform(self,discretize_list):\n",
    "        for i in discretize_list.columns:\n",
    "            replace_coloumn = discretize_list[i].unique()\n",
    "            replace_coloumn.sort()\n",
    "            lst = list(replace_coloumn)\n",
    "            ip_dict = dict(zip(lst, range(len(lst))))\n",
    "            discretize_list[i] = discretize_list[i].replace(ip_dict)\n",
    "        return discretize_list\n",
    "    \n",
    "    def MergeFeatures(self,selectDataDiscretiz_list,disSelectData_list):  ## Merge Discretized Data with Original Data\n",
    "        self.dataDiscretize_list = np.concatenate([selectDataDiscretiz_list,disSelectData_list],axis = 1)\n",
    "        return self.dataDiscretize_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discretization Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discretization_utility:\n",
    "    def __init__(self, continuous_data, discretize_coloumn):\n",
    "        self.continuous_data_dataframe = continuous_data\n",
    "        self.discretize_coloumn = discretize_coloumn\n",
    "\n",
    "    # Deprecated\n",
    "#     def SelectFeatures(self): ##Split Specific to Discretize\n",
    "#         idx_IN_columns = self.discretize_coloumn\n",
    "#         idx_OUT_columns = [i for i in range(np.shape(self.training_data)[1]) if i not in idx_IN_columns]\n",
    "#         selectData_list = self.training_data[:,idx_IN_columns]\n",
    "#         disSelectData_list = self.training_data[:,idx_OUT_columns]\n",
    "#         return selectData_list , disSelectData_list\n",
    "    \n",
    "    def SelectFeatures(self): ##Split Specific to Discretize\n",
    "        idx_IN_columns = self.discretize_coloumn\n",
    "        idx_OUT_columns = [i for i in range(np.shape(self.continuous_data_dataframe)[1]) if i not in idx_IN_columns]\n",
    "        selectData_list = self.continuous_data_dataframe.iloc[:,idx_IN_columns]\n",
    "        disSelectData_list = self.continuous_data_dataframe.iloc[:,idx_OUT_columns]\n",
    "        return selectData_list , disSelectData_list\n",
    "    \n",
    "    def PrintFirstFiveData(self,data,dataname): ##Split Specific to Discretize\n",
    "        #print(\"[\"+str(dataname)+\"]\")\n",
    "        #print(data.head(5))\n",
    "        return 0\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discretization with R\n",
    "R package'Discretization'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discretization_rpy2:\n",
    "    ## Input:X_train,y_train,X_test,y_test,discretize_coloumn,method\n",
    "    ## Output: Discretize_X_train_dataframe, y_train_dataframe, Discretize_X_test_dataframe, y_test_dataframe\n",
    "    \n",
    "    def discretize(X_train,y_train,X_test,y_test,discretize_coloumn,method):\n",
    "\n",
    "        # Declare Discretizer_rpy2 (Select Continuous Feature, PrintFirstFive)\n",
    "        discretize_train = Discretization_utility(X_train,discretize_coloumn)\n",
    "\n",
    "        # Select Continuous Feature (Training Data Continuous Feature)\n",
    "        X_train_continuousData_list, X_train_catrgorialData_list  = discretize_train.SelectFeatures() #Devide Discretize Coloumns\n",
    "\n",
    "\n",
    "        # Convert data to Dataframe for R Package \"Discretization\"\n",
    "        ## R 'Discretization' require Continuous Data(X_Train_SelectData) and Target(y_Train) in the last column\n",
    "        X_train_continuousData_dataframe = pd.DataFrame(X_train_continuousData_list)\n",
    "        y_train_dataframe = pd.DataFrame(y_train)\n",
    "\n",
    "        # Combine Select Continuous with Target\n",
    "        X_y_train_continuousData_dataframe = pd.concat([X_train_continuousData_dataframe, y_train_dataframe],axis=1)\n",
    "        X_y_train_continuousData_dataframe.columns = range(X_y_train_continuousData_dataframe.shape[1]) #Reshape for column index\n",
    "        discretize_train.PrintFirstFiveData(X_y_train_continuousData_dataframe,\"X_y_train_continuousData_dataframe\")\n",
    "\n",
    "\n",
    "        # Import R Package\n",
    "        discretization = importr(\"discretization\")\n",
    "        disc_Topdown = robjects.r(\"disc.Topdown\")\n",
    "\n",
    "        print(\"-------------------------------\"+method+\" -----------------------------\")\n",
    "\n",
    "        # Discretize (R Package)\n",
    "        ## Input: pandas.DataFrame  Output: rpy2.DataFrame\n",
    "        if method == 'MDLP_R':\n",
    "            X_y_train_disData_rpy2dataframe = discretization.mdlp(X_y_train_continuousData_dataframe)\n",
    "        elif method == 'CAIM_R':\n",
    "            X_y_train_disData_rpy2dataframe = discretization.disc_Topdown(X_y_train_continuousData_dataframe, method=1)\n",
    "        elif method == 'ChiMerge_R':\n",
    "            X_y_train_disData_rpy2dataframe = discretization.chiM(X_y_train_continuousData_dataframe, alpha = 0.05)\n",
    "        elif method == 'CACC_R':\n",
    "            X_y_train_disData_rpy2dataframe = discretization.disc_Topdown(X_y_train_continuousData_dataframe, method=2)\n",
    "        elif method == 'Chi2_R':\n",
    "            X_y_train_disData_rpy2dataframe = discretization.chi2(X_y_train_continuousData_dataframe,0.5,0.05)\n",
    "\n",
    "        # Transfer rpy2.DataFrame to pandas.DataFrame\n",
    "        X_y_train_disData_dataframe = pandas2ri.ri2py(X_y_train_disData_rpy2dataframe[1])\n",
    "        discretize_train.PrintFirstFiveData(X_y_train_disData_dataframe,\"X_y_train_disData_dataframe\")\n",
    "\n",
    "\n",
    "        # Select the data(without target) in Combine_X_y_train_dis_dataframe \n",
    "        X_train_disData_dataframe = X_y_train_disData_dataframe.iloc[:,:-1]\n",
    "        discretize_train.PrintFirstFiveData(X_train_disData_dataframe,\"X_train_disData_dataframe\")\n",
    "\n",
    "\n",
    "        # Merge dis_feature & categeorial_feature\n",
    "        X_train_categorialData_dataframe = pd.DataFrame(X_train_catrgorialData_list)\n",
    "        discretize_train.PrintFirstFiveData(X_train_categorialData_dataframe,\"X_train_categorialData_dataframe\")            \n",
    "        Discretize_X_train_dataframe = pd.concat([X_train_disData_dataframe, X_train_categorialData_dataframe],axis = 1)\n",
    "        Discretize_X_train_dataframe.columns = range(Discretize_X_train_dataframe.shape[1])\n",
    "        discretize_train.PrintFirstFiveData(Discretize_X_train_dataframe,\"Discretize_X_train_dataframe\")\n",
    "\n",
    "\n",
    "        # --------------------------------------Discretize Testing Data----------------------------------------------------\n",
    "\n",
    "        # Enable Cutpoint for X_test (No Target)\n",
    "\n",
    "        ## Declare Discretization_utility\n",
    "        discretize_test = Discretization_utility(X_test,discretize_coloumn)\n",
    "\n",
    "        ## Select Continuous Feature (Testing Data Continuous Feature)\n",
    "        ## Return: List of data\n",
    "        X_test_continuousData_list, X_test_catrgorialData_list  = discretize_test.SelectFeatures() #Devide Discretize Coloumns\n",
    "\n",
    "\n",
    "        ## Prepare X_test to enable cutpoint\n",
    "        X_test_continuousData_dataframe  = pd.DataFrame(X_test_continuousData_list)\n",
    "        discretize_train.PrintFirstFiveData(X_test_continuousData_dataframe,\"X_test_continuousData_dataframe\")\n",
    "\n",
    "\n",
    "        ## Get Cutpoint (Transfer to numpy array)\n",
    "        cutpoint_bins = X_y_train_disData_rpy2dataframe[0]\n",
    "        #cutpoint_bins = np.array(cutpoint)\n",
    "        #print(\"Original Cutbins\")\n",
    "        #print(cutpoint_bins)\n",
    "\n",
    "\n",
    "        ## Declare dataframe for store data after discretize\n",
    "        X_test_disData_dataframe = pd.DataFrame()\n",
    "\n",
    "        # Iterate the cutbin to pd.cut the data\n",
    "        for idx, val in enumerate(X_test_continuousData_dataframe):\n",
    "            if cutpoint_bins[idx][0] == \"All\":\n",
    "                #print(str(idx)+\"_ALL\")\n",
    "                X_test_disData_dataframe[idx] = pd.cut(X_test_continuousData_dataframe.iloc[:,idx], bins =1 , labels = [1],include_lowest=True )    \n",
    "            else:        \n",
    "                #print(str(idx)+\"_NOTALL\")\n",
    "                cutpoint_bins[idx] = np.sort(cutpoint_bins[idx])\n",
    "                #print(type(cutpoint_bins[idx]))\n",
    "                cutpoint_with_infiniti = np.insert (np.insert(cutpoint_bins[idx],0, (-np.inf),0),len(cutpoint_bins[idx])+1,(np.inf))\n",
    "                cutpoint_labels = list(range(1, len(cutpoint_with_infiniti)))\n",
    "                #print(cutpoint_labels)\n",
    "\n",
    "                X_test_disData_dataframe[idx] = pd.cut(X_test_continuousData_dataframe.iloc[:,idx], bins = cutpoint_with_infiniti,labels=cutpoint_labels,include_lowest=True)\n",
    "        discretize_train.PrintFirstFiveData(X_test_disData_dataframe,\"X_test_disData_dataframe\")\n",
    "\n",
    "\n",
    "        # Merge dis_feature & categeorial_feature\n",
    "        X_test_categorialData_dataframe = pd.DataFrame(X_test_catrgorialData_list)\n",
    "        discretize_train.PrintFirstFiveData(X_test_categorialData_dataframe,\"X_test_categorialData_dataframe\")\n",
    "\n",
    "        Discretize_X_test_dataframe = pd.concat([X_test_disData_dataframe, X_test_categorialData_dataframe],axis=1)\n",
    "        Discretize_X_test_dataframe.columns = range(Discretize_X_test_dataframe.shape[1])\n",
    "        discretize_train.PrintFirstFiveData(Discretize_X_test_dataframe,\"Discretize_X_test_dataframe\")\n",
    "\n",
    "\n",
    "        # Convert Target to Dataframe\n",
    "        y_train_dataframe = pd.DataFrame(y_train)\n",
    "        y_test_dataframe = pd.DataFrame(y_test)\n",
    "        \n",
    "        return Discretize_X_train_dataframe, y_train_dataframe, Discretize_X_test_dataframe, y_test_dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KFoldFuntion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KFoldFuntion:\n",
    "    # classifier, \n",
    "    # linear_svc,'linear_svc','','None','None','Dis-None', data_list, target_list, fold\n",
    "    def __init__(self, classifier, classifier_name, discretization_method, fs_method, method_order, data_list, target_list, fold, discretize_coloumn):\n",
    "        self.X = data_list\n",
    "        self.y = target_list\n",
    "        self.fold = fold\n",
    "        self.outcomes_acc = []\n",
    "        self.outcomes_auc = []\n",
    "        self.outcomes_typeII = []\n",
    "        self.outcomes_typeI = []\n",
    "        self.fold_result_list = []\n",
    "        self.outcomes_minority = []\n",
    "        self.outcomes_majority = []\n",
    "        self.discretization_method = discretization_method  # (None, MDLP, CAIM)\n",
    "        self.fs_method = fs_method  # (None, C4.5, PCA, GA)\n",
    "        self.method_order = method_order # (None-None, Dis-None, Dis-FS, FS-None, FS-Dis)\n",
    "        self.classifier = classifier\n",
    "        self.classifier_name = classifier_name\n",
    "        self.discretize_coloumn = discretize_coloumn\n",
    "    \n",
    "    def Classify(self):\n",
    "        # Main function\n",
    "        ## Cross Validation, Discretization, (Feature Selection), Classifier\n",
    "        \n",
    "        kf = KFold(n_splits=self.fold,random_state=np.random, shuffle=True)\n",
    "        #kf = StratifiedKFold(n_splits=self.fold)\n",
    "        for train_index, test_index in kf.split(self.X):\n",
    "            X_train, X_test = self.X[train_index], self.X[test_index] #X_train: training data X_test: testing data\n",
    "            y_train, y_test = self.y[train_index], self.y[test_index] #y_train: training data answer y_test: testing data answer\n",
    "            \n",
    "            # Convert to Dataframe\n",
    "            X_train_dataframe = pd.DataFrame(X_train)\n",
    "            X_test_dataframe  = pd.DataFrame(X_test)\n",
    "            y_train_dataframe = pd.DataFrame(y_train)\n",
    "            y_test_dataframe  = pd.DataFrame(y_test)\n",
    "            \n",
    "            # Decide the process order (Dis-FS or FS-None)\n",
    "            first_method, second_method = self.method_order.split('-')\n",
    "            \n",
    "            # Pre-Proecessing\n",
    "            if first_method== 'Dis':\n",
    "                print(\"Discretization\")\n",
    "                X_train_dataframe, y_train_dataframe, X_test_dataframe, y_test_dataframe = Discretization_rpy2.discretize(X_train_dataframe,y_train_dataframe,X_test_dataframe,y_test_dataframe,self.discretize_coloumn,self.discretization_method)\n",
    "            elif first_method== 'FS':\n",
    "                print(\"Feature Selection\")\n",
    "                \n",
    "            if second_method== 'Dis':\n",
    "                print(\"Discretization\")\n",
    "                X_train_dataframe, y_train_dataframe, X_test_dataframe, y_test_dataframe = Discretization_rpy2.discretize(X_train_dataframe,y_train_dataframe,X_test_dataframe,y_test_dataframe,self.discretize_coloumn,self.discretization_method)\n",
    "            elif second_method== 'FS':\n",
    "                print(\"Feature Selection\")\n",
    "            \n",
    "          \n",
    "            # Feature Preprocessing (Discretization, Feature Selection)\n",
    "\n",
    "\n",
    "            # Discretization()\n",
    "            ## Input: X_train_dataframe, y_train_dataframe, X_test_dataframe, y_test_dataframe, discretize_coloumn, discretization_method\n",
    "            ## Output: Discretize_X_train_dataframe, y_train_dataframe, Discretize_X_test_dataframe, y_test_dataframe\n",
    "\n",
    "            # Feature Selection()\n",
    "            ## Input: X_train_dataframe, y_train_dataframe, X_test_dataframe, y_test_dataframe, discretize_coloumn, method\n",
    "            ## Output: X_train_dataframe,X_test_dataframe,y_train_dataframe,y_test_dataframe\n",
    "\n",
    "\n",
    "            # Prediction (Discretize_X_train_dataframe, y_train_dataframe, Discretize_X_test_dataframe, y_test_dataframe)\n",
    "            predictions,proba = self.Classification(X_train_dataframe,y_train_dataframe,\n",
    "                                                    X_test_dataframe,y_test_dataframe)\n",
    "            self.StoreFoldResult(y_test_dataframe,predictions,proba)\n",
    "                \n",
    "        return self.PrintTotalResult()   \n",
    "                      \n",
    "    def Classification(self,X_train_dataframe,y_train_dataframe,X_test_dataframe,y_test_dataframe):\n",
    "        \n",
    "        # Convert Dataframe column from int to str (for xgboost)\n",
    "        X_train_dataframe.columns = X_train_dataframe.columns.astype(str)\n",
    "        y_train_dataframe.columns = y_train_dataframe.columns.astype(str)\n",
    "        X_test_dataframe.columns = X_test_dataframe.columns.astype(str)\n",
    "        y_test_dataframe.columns = y_test_dataframe.columns.astype(str)\n",
    "        \n",
    "        # Convert Dataframe type from int to float (some classifier doesn't accept different dtype in same dataframe)\n",
    "        X_train_dataframe = X_train_dataframe.astype('float')\n",
    "        y_train_dataframe = y_train_dataframe.astype('float')\n",
    "        X_test_dataframe = X_test_dataframe.astype('float')\n",
    "        y_test_dataframe = y_test_dataframe.astype('float')\n",
    "        \n",
    "        \n",
    "        clf = self.classifier\n",
    "        clf.fit(X_train_dataframe, y_train_dataframe[\"0\"].ravel())\n",
    "        predictions = clf.predict(X_test_dataframe)\n",
    "        proba = clf.predict_proba(X_test_dataframe)[:, 1]\n",
    "        return predictions,proba\n",
    "\n",
    "    \n",
    "    def StoreFoldResult(self,y_test_dataframe,predictions,proba):\n",
    "        \n",
    "        #Accuracy Score\n",
    "        accuracy = accuracy_score(y_test_dataframe, predictions)\n",
    "        self.outcomes_acc.append(accuracy)\n",
    "        \n",
    "        #AUC Score\n",
    "        auc = roc_auc_score(y_test_dataframe, proba)\n",
    "        self.outcomes_auc.append(auc)\n",
    "        \n",
    "        #Type II Error\n",
    "        TN, FP, FN, TP = confusion_matrix(y_test_dataframe, predictions).ravel()\n",
    "        typeII = FN/(TP+FN)\n",
    "        typeI = FP/(FP+TN)\n",
    "        self.outcomes_typeII.append(typeII)\n",
    "        self.outcomes_typeI.append(typeI)\n",
    "        \n",
    "        #Majority, Minority (Count)\n",
    "        unique, counts = np.unique(y_test_dataframe, return_counts=True)\n",
    "        dict(zip(unique, counts))\n",
    "        \n",
    "        proportion = np.unique(y_test_dataframe, return_counts=True)\n",
    "        majority_proportion = proportion[1][0]/(self.X.shape[0]/self.fold)\n",
    "        minority_proportion = proportion[1][1]/(self.X.shape[0]/self.fold)\n",
    "        self.outcomes_majority.append(proportion[1][0])\n",
    "        self.outcomes_minority.append(proportion[1][1])\n",
    "\n",
    "        \n",
    "        # Plot fold_result_list \n",
    "        each_fold_result_list = [accuracy,auc,typeI,typeII,majority_proportion,minority_proportion]\n",
    "        self.fold_result_list.append(each_fold_result_list)\n",
    "    \n",
    "    def PrintTotalResult(self):\n",
    "        \n",
    "        mean_outcome_acc = np.mean(self.outcomes_acc)\n",
    "        print(\"Mean Accuracy: {0}\".format(mean_outcome_acc))\n",
    "        print(\"Mean Accuracy\"+ str(self.outcomes_acc))\n",
    "        \n",
    "        mean_outcome_auc = np.mean(self.outcomes_auc)\n",
    "        print(\"Mean Auc: {0}\".format(mean_outcome_auc))\n",
    "        print(\"Mean Auc\"+ str(self.outcomes_auc))\n",
    "        \n",
    "        mean_outcomes_typeII = np.mean(self.outcomes_typeII)\n",
    "        print(\"Mean TypeII: {0}\".format(mean_outcomes_typeII))\n",
    "        print(\"Mean TypeII\"+ str(self.outcomes_typeII))\n",
    "        \n",
    "        mean_outcomes_typeI = np.mean(self.outcomes_typeI)\n",
    "        print(\"Mean TypeI: {0}\".format(mean_outcomes_typeI))\n",
    "        print(\"Mean TypeI\"+ str(self.outcomes_typeI))\n",
    "        \n",
    "        lock.acquire()\n",
    "        \n",
    "        # Print Each Fold Plot\n",
    "        self.PrintPlotEachFold(self.fold_result_list,\"Result\")\n",
    "        \n",
    "        lock.release()\n",
    "        \n",
    "        return mean_outcome_acc, mean_outcome_auc, mean_outcomes_typeI, mean_outcomes_typeII\n",
    "    \n",
    "    def PrintPlotEachFold(self,plot_data,metrics_name):\n",
    "        \n",
    "        #Trasnfer Type \n",
    "        plot_data = np.array(plot_data)\n",
    "        \n",
    "        #Set Each Line Data\n",
    "        plt.plot(plot_data[:,0],label='acc')\n",
    "        plt.plot(plot_data[:,1],label='auc')\n",
    "        plt.plot(plot_data[:,2],label='type I')\n",
    "        plt.plot(plot_data[:,3],label='type II')\n",
    "        plt.plot(plot_data[:,4],label='maj', marker='o')\n",
    "        plt.plot(plot_data[:,5],label='min', marker='o')\n",
    "        \n",
    "        #Set Graph Information\n",
    "        title = '{metrics_name} with {fold} folds-{discretization_method}-{fs_method}-({method_order})-{classifier_name}'.format(\n",
    "            metrics_name=metrics_name, fold=self.fold,discretization_method=self.discretization_method,fs_method=self.fs_method,method_order=self.method_order,classifier_name=self.classifier_name )\n",
    "        plt.title(title)\n",
    "        plt.xlabel('Folds')\n",
    "        plt.ylabel('percertange')\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def CompareMethodMeanResult(data_name, clf_name, rounds,result_10times_baseline,result_10times_MDLP,result_10times_CAIM,result_10times_ChiMerge_SC,result_10times_CACC,result_10times_Chi2):\n",
    "    # Compare different Preprocessing (Dis-FS) figure\n",
    "    labels = ['ACC', 'AUC', 'TYPEI', 'TYPEII']\n",
    "    x = np.arange(len(labels))  # the label locations\n",
    "    width = 0.15  # the width of the bars\n",
    "\n",
    "    result_10times_baseline_mean = np.around( np.mean(result_10times_baseline, axis=0), decimals=3)\n",
    "    result_10times_MDLP_mean =  np.around( np.mean(result_10times_MDLP, axis=0), decimals=3)\n",
    "    result_10times_CAIM_mean =  np.around( np.mean(result_10times_CAIM, axis=0), decimals=3)\n",
    "    result_10times_ChiMerge_SC_mean =  np.around( np.mean(result_10times_ChiMerge_SC, axis=0), decimals=3)\n",
    "    result_10times_CACC_mean =  np.around( np.mean(result_10times_CACC, axis=0), decimals=3)\n",
    "    result_10times_Chi2_mean =  np.around( np.mean(result_10times_Chi2, axis=0), decimals=3)\n",
    "    #result_10times_ChiMerge_RG_mean =  np.around( np.mean(result_10times_ChiMerge_RG, axis=0), decimals=3)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(15, 10))\n",
    "    rects1 = ax.bar(x , result_10times_baseline_mean, width, label='Baseline')\n",
    "    rects2 = ax.bar(x +width, result_10times_MDLP_mean, width, label='MDLP_R')\n",
    "    rects3 = ax.bar(x +width*2, result_10times_CAIM_mean, width, label='CAIM_R')\n",
    "    rects4 = ax.bar(x +width*3, result_10times_ChiMerge_SC_mean, width, label='ChiMerge_R')\n",
    "    rects5 = ax.bar(x +width*4, result_10times_CACC_mean, width, label='CACC_R')\n",
    "    rects6 = ax.bar(x +width*5, result_10times_Chi2_mean, width, label='Chi2_R')\n",
    "    #rects5 = ax.bar(x +width*4, result_10times_ChiMerge_RG_mean, width, label='ChiMerge_RG')\n",
    "\n",
    "    # Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "    ax.set_ylabel('Percentage')\n",
    "    data_name, clf_name, rounds\n",
    "    title = 'Compare Result-{data_name}-{classifier_name}'.format(data_name=data_name,classifier_name=clf_name)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xticks(x+width*2)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.legend(bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "    def autolabel(rects):\n",
    "        \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
    "        for rect in rects:\n",
    "            height = rect.get_height()\n",
    "            ax.annotate('{}'.format(height),\n",
    "                        xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                        xytext=(0, 5),  # 3 points vertical offset\n",
    "                        textcoords=\"offset points\",\n",
    "                        ha='center', va='bottom', size = 12)\n",
    "    autolabel(rects1)\n",
    "    autolabel(rects2)\n",
    "    autolabel(rects3)\n",
    "    autolabel(rects4)\n",
    "    autolabel(rects5)\n",
    "    autolabel(rects6)\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    file_time = time.strftime(\"%Y-%m-%d-%H%M%S\", time.localtime()) \n",
    "    file_name = \"results/{title}_{file_timeA}.png\".format(file_timeA = file_time, title= title)\n",
    "    print(title)\n",
    "    fig.savefig(file_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResultEachMethodLineChart(result, method_name,data_name, classifier_name):\n",
    "    result = np.array(result)\n",
    "    \n",
    "    plt.plot(result[:,0], label='Acc', marker='o')\n",
    "    plt.plot(result[:,1], label='Auc', marker='o')\n",
    "    plt.plot(result[:,2], label='TypeI', marker='o')\n",
    "    plt.plot(result[:,3], label='TypeII', marker='o')\n",
    "    plt.legend(bbox_to_anchor=(1, 0.5))\n",
    "    plt.ylabel('Percertange')\n",
    "    plt.xlabel('Rounds')\n",
    "    title = 'Each Rounds-{data_name}-{method_name}-{classifier_name}'.format(data_name=data_name,method_name=method_name,classifier_name=classifier_name)\n",
    "    plt.title(title)\n",
    "    \n",
    "    \n",
    "    file_time = time.strftime(\"%Y-%m-%d-%H%M%S\", time.localtime()) \n",
    "    #plt.savefig('results/{title}_{file_timeA}.png'.format(file_timeA = file_time, title= title, method_name=method_name, classifier_name=classifier_name), bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Classification Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC, LinearSVC , libsvm\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from logitboost import LogitBoost\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Classify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run 10 Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Classifcation Method\n",
    "linear_svc = CalibratedClassifierCV(LinearSVC(max_iter=7000))\n",
    "svmlinear = SVC(kernel='linear', probability=True)\n",
    "svmrbf = SVC(kernel='rbf', probability=True)\n",
    "DecisionTreeClassifier = tree.DecisionTreeClassifier()\n",
    "RandomForest = RandomForestClassifier()\n",
    "logisticRegression = LogisticRegression()\n",
    "mlp = MLPClassifier()\n",
    "xgBoost = xgb.XGBClassifier()\n",
    "GaussianNaiveBayes = GaussianNB()\n",
    "MultinomialNaiveBayes = MultinomialNB()\n",
    "ComplementNaiveBayes = ComplementNB()\n",
    "lboost = LogitBoost()\n",
    "ada = AdaBoostClassifier()\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "##########################################\n",
    "#svmpoly = SVC(kernel='poly', probability=True)\n",
    "#neigh = KNeighborsRegressor(n_neighbors=5)\n",
    "#linearRegression= LinearRegression()\n",
    "\n",
    "def run10times(classifier_list,classifier_name_list):\n",
    "\n",
    "    classifier_list = [classifier_list]\n",
    "    classifier_name_list = [classifier_name_list]\n",
    "    classifier_result_list = []\n",
    "    \n",
    "    for idx,classifi in enumerate(classifier_list):\n",
    "        result_list = []\n",
    "        rounds = 2\n",
    "        clf_name = classifier_name_list[idx]\n",
    "        for i in range(1,rounds):\n",
    "\n",
    "            result_list.clear()\n",
    "            result_10times_baseline = []\n",
    "            result_10times_MDLP = []\n",
    "            result_10times_CAIM = []\n",
    "            result_10times_ChiMerge_SC = []\n",
    "            result_10times_ChiMerge_RG = []\n",
    "            result_10times_CACC = []\n",
    "            result_10times_Chi2 = []\n",
    "            runnung_time_list = []\n",
    "\n",
    "            clf = classifi\n",
    "            fold = 5\n",
    "\n",
    "            start_time = time.time()\n",
    "            result_eachtimes_baseline = KFoldFuntion(clf, clf_name, 'None','None','None-None', data_list, target_list, fold, discretize_coloumn).Classify()\n",
    "            result_10times_baseline.append(result_eachtimes_baseline)\n",
    "            runnung_time_list.append(time.time() - start_time)\n",
    "\n",
    "            start_time = time.time()\n",
    "            result_eachtimes_MDLP = KFoldFuntion(clf, clf_name, 'MDLP_R','None','Dis-None', data_list, target_list, fold, discretize_coloumn).Classify()\n",
    "            result_10times_MDLP.append(result_eachtimes_MDLP)\n",
    "            runnung_time_list.append(time.time() - start_time)\n",
    "\n",
    "            start_time = time.time()\n",
    "            result_eachtimes_CAIM = KFoldFuntion(clf, clf_name, 'CAIM_R','None','Dis-None', data_list, target_list, fold, discretize_coloumn).Classify()\n",
    "            result_10times_CAIM.append(result_eachtimes_CAIM)\n",
    "            runnung_time_list.append(time.time() - start_time)\n",
    "\n",
    "            start_time = time.time()\n",
    "            result_eachtimes_ChiMerge_SC = KFoldFuntion(clf, clf_name, 'ChiMerge_R','None','Dis-None', data_list, target_list, fold, discretize_coloumn).Classify()\n",
    "            result_10times_ChiMerge_SC.append(result_eachtimes_ChiMerge_SC)\n",
    "            runnung_time_list.append(time.time() - start_time)\n",
    "            \n",
    "            start_time = time.time()\n",
    "            result_eachtimes_CACC = KFoldFuntion(clf, clf_name, 'CACC_R','None','Dis-None', data_list, target_list, fold, discretize_coloumn).Classify()\n",
    "            result_10times_CACC.append(result_eachtimes_CACC)\n",
    "            runnung_time_list.append(time.time() - start_time)\n",
    "            \n",
    "            start_time = time.time()\n",
    "            result_eachtimes_Chi2 = KFoldFuntion(clf, clf_name, 'Chi2_R','None','Dis-None', data_list, target_list, fold, discretize_coloumn).Classify()\n",
    "            result_10times_Chi2.append(result_eachtimes_Chi2)\n",
    "            runnung_time_list.append(time.time() - start_time)\n",
    "    \n",
    "        \n",
    "        # Thread Lock\n",
    "        lock.acquire()\n",
    "        \n",
    "        \n",
    "        # Compare Chart (Same Classifier)\n",
    "        CompareMethodMeanResult(data_name, clf_name, rounds,result_10times_baseline,result_10times_MDLP,result_10times_CAIM,result_10times_ChiMerge_SC,result_10times_CACC,result_10times_Chi2)\n",
    "\n",
    "\n",
    "        # Compare Chart (Same Classifier)\n",
    "        ResultEachMethodLineChart(result_10times_baseline,\"Baseline\",data_name,clf_name)\n",
    "        ResultEachMethodLineChart(result_10times_MDLP,\"MDLP_R\",data_name,clf_name)\n",
    "        ResultEachMethodLineChart(result_10times_CAIM,\"CAIM_R\",data_name,clf_name)\n",
    "        ResultEachMethodLineChart(result_10times_ChiMerge_SC,\"ChiMerge_R\",data_name,clf_name)\n",
    "        ResultEachMethodLineChart(result_10times_CACC,\"CACC_R\",data_name,clf_name)\n",
    "        ResultEachMethodLineChart(result_10times_Chi2,\"Chi2_R\",data_name,clf_name)\n",
    "\n",
    "        result_list.append(np.mean(result_10times_baseline, axis=0))\n",
    "        result_list.append(np.mean(result_10times_MDLP, axis=0))\n",
    "        result_list.append(np.mean(result_10times_CAIM, axis=0))\n",
    "        result_list.append(np.mean(result_10times_ChiMerge_SC, axis=0))\n",
    "        result_list.append(np.mean(result_10times_CACC, axis=0))\n",
    "        result_list.append(np.mean(result_10times_Chi2, axis=0))\n",
    "\n",
    "        # Single Classify Method \n",
    "        result_with_method = pd.DataFrame(result_list, index=['Baseline','MDLP_R','CAIM_R','ChiMerge_R','CACC_R','Chi2_R'], columns=['Accuracy','AUC','TypeI','TypeII'])\n",
    "        result_with_method['Time(Second)'] = runnung_time_list\n",
    "        print(result_with_method)\n",
    "\n",
    "        file_time = time.strftime(\"%Y-%m-%d-%H%M%S\", time.localtime()) \n",
    "        file_name = \"Classifier_result_list_{fold}Fold_{data_name}_{clf_name}_{file_timeA}.xlsx\".format(fold = fold, file_timeA = file_time,data_name=data_name,clf_name=clf_name)\n",
    "        pd.DataFrame(result_with_method).to_excel(\"resultsexcel/\"+file_name)\n",
    "        \n",
    "        \n",
    "        # Thread Unlock\n",
    "        lock.release()\n",
    "    \n",
    "\n",
    "\n",
    "t0 = Thread(target=run10times,args=(svmlinear,\"svmlinear\"))\n",
    "t1 = Thread(target=run10times,args=(linear_svc,\"linear_svc\"))\n",
    "t2 = Thread(target=run10times,args=(svmrbf,\"svmrbf\"))\n",
    "t3 = Thread(target=run10times,args=(DecisionTreeClassifier,\"DecisionTreeClassifier\"))\n",
    "t4 = Thread(target=run10times,args=(RandomForest,\"RandomForest\"))\n",
    "t5 = Thread(target=run10times,args=(logisticRegression,\"logisticRegression\"))\n",
    "t6 = Thread(target=run10times,args=(mlp,\"mlp\"))\n",
    "t7 = Thread(target=run10times,args=(xgBoost,\"xgBoost\"))\n",
    "t8 = Thread(target=run10times,args=(GaussianNaiveBayes,\"GaussianNaiveBayes\"))\n",
    "t9 = Thread(target=run10times,args=(lboost,\"LogitBoost\"))\n",
    "t10 = Thread(target=run10times,args=(ada,\"AdaBoost\"))\n",
    "t11 = Thread(target=run10times,args=(knn,\"KNN\"))\n",
    "\n",
    "\n",
    "#thread_list = [t1,t2,t3,t4,t5,t6,t7,t8,t9,t10,t0]\n",
    "thread_list = [t1]\n",
    "#thread_list = [t1,t2,t3,t4,t5,t6,t7,t8,t9,t10,t11]\n",
    "#thread_list = [t11,t10,t9,t7,t8]\n",
    "\n",
    "#程式開始\n",
    "for item in thread_list:\n",
    "    item.start()\n",
    "print(\"\\n程式開始\")\n",
    "\n",
    "\n",
    "#程式結束\n",
    "for item in thread_list:\n",
    "    item.join()\n",
    "print(\"\\n程式結束\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#############################################################################YEE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Record Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "print(\"Mean : {0}\".format(np.mean(result_10times_baseline, axis=0))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "print(\"Mean : {0}\".format(np.mean(result_10times_MDLP, axis=0))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(\"Mean : {0}\".format(np.mean(result_10times_CAIM, axis=0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(\"Mean : {0}\".format(np.mean(result_10times_ChiMerge_SC, axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#ResultEachMethodLineChart(result_10times_ChiMerge_RG,\"ChiMerge_RG\",data_name,clf_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
